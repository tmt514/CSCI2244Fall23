{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Syllabus","text":""},{"location":"#csci-2244-randomness-and-computation","title":"CSCI 2244 Randomness and Computation","text":"<p>Welcome to the class page! You can find most of course-related materials here.</p>"},{"location":"#staff-and-office-hours","title":"Staff and Office Hours","text":"<ul> <li>Instructor: Shang-En Huang.<ul> <li>Office Hours: Monday 4-5pm; Friday 10-11am; other times request by email.</li> <li>Location: 428G.</li> </ul> </li> <li>Teaching Assistant: TBD.</li> <li>Teaching Assistant: TBD.</li> </ul>"},{"location":"#references","title":"References","text":""},{"location":"#textbook","title":"Textbook","text":"<p>We will use the book written by Professor Sergio A. Alvarez as the main textbook.</p>"},{"location":"#supplementary-readings","title":"Supplementary Readings","text":"<ul> <li>Grinsted and Snell's Introduction to Probability [pdf] [page]</li> <li>Professor Howard Straubing's CSCI2244-Spring2019 Course Site</li> <li>Professor Sergio A. Alverez's CSCI2244-Spring2023 Course Site</li> </ul>"},{"location":"#grading","title":"Grading","text":"<ul> <li>27% Homeworks: There will be 12 problem sets. The highest 9 PS scores count towards to your homework grade.</li> <li>18% Exam 1. (50 minutes)</li> <li>18% Exam 2. (50 minutes)</li> <li>36% Exam 3. (2 hours)</li> <li>1% if I can recognize you at the end of the semester.</li> </ul>"},{"location":"#homeworks","title":"Homeworks","text":"<p>There will be 12 problem sets, and each problem set is released at least 168 hours before due. The typical deadline is 10PM (ET) but I allow submissions up to 11:59PM (ET) on the same day. I do not accept submissions later than 11:59PM. This is a hard constraint, no excuse, sorry. (That's why we dropped 3 PS scores!)</p> <p>Each homework is worth of 20 points, and usually consists of three parts:</p> <ol> <li>Writing Assignments (12 points): mostly mathematical proofs.</li> <li>Canvas Quizzes (4 points): concepts &amp; calculations.</li> <li>Programming Assignments (4 points): experiments &amp; empirical analysis.</li> </ol> <p>Occasionally there are bonus questions. However, bonus questions are usually significantly more challenging, and require much more effort.</p>"},{"location":"#typesetting-your-homework-submissions","title":"Typesetting Your Homework Submissions","text":"<p>All mathematical expressions must be typesetted. A badly typesetted submission could get a desk-rejection without any credit. The easiest way to typeset the homeworks in this course is to use LaTeX. We will provide LaTeX templates for each homework assignment and you can utilize Overleaf to write down the solutions.</p>"},{"location":"#ipython-notebooks","title":"IPython Notebooks","text":"<p>All programming assignments will be in the IPython Notebook format(<code>.ipynb</code>). We highly recommend you to install Jupyter Notebook on your computer. However, installing Jupyter Notebook locally is not necessary. Sometimes there could be technical issues (that would be good learning experiences for the hardcore CS stuff). If you encounter such a situation right before the homework deadlines, there are other options for you. For example, you can utilize Google Colab which provides basic computing resources in ipython format that suit our needs.</p>"},{"location":"#exams","title":"Exams","text":"<ul> <li>Closed book exams.</li> <li>I will provide one common info sheet and unlimited scratch papers for you.</li> <li>You are allowed to bring 1 page (2-sided) of hand written cheat sheet.</li> </ul>"},{"location":"#academic-honesty","title":"Academic Honesty","text":"<p>You should be responsible for all the mathematical works and the submitted codes. Please read the Boston College academic integrity policy. Dishonest behaviors may be reported and then reviewed by the Academic Integrity Board.</p>"},{"location":"#services-for-students-with-disabilities","title":"Services for Students with Disabilities","text":"<p>Please see this page for the students with disabilities who need help.</p>"},{"location":"#wellness","title":"Wellness","text":"<p>Your health and well-being are important! Please be aware that Boston College provides a range of support services for students who need help on mental health. Please see this page.</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<pre><code>graph LR\n  subgraph prerequisite\n    direction TB\n    A(CSCI 2243 &lt;br/&gt;&lt;b&gt;Logic and Computation&lt;/b&gt;) -.-|OR| C(MATH 2216 &lt;br/&gt;&lt;b&gt;Intro to abstract Math&lt;/b&gt;)\n  end\n  P(CSCI 1101 &lt;br/&gt;&lt;b&gt;Computer Science I&lt;/b&gt;) --&gt; prerequisite\n  prerequisite --&gt; D(CSCI 2244 &lt;br/&gt;&lt;b&gt;Randomness and Computation&lt;/b&gt;)\n  click C \"http://fmwww.bc.edu/gross/MATH2216/\" \"A good resource to MATH 2216.\"</code></pre> <ul> <li>We will need a little bit of MATH 1101/1102 (Calculus I/II). For example, please don't be afraid of the symbols in the following expression:</li> </ul> \\[ \\int_{-\\infty}^\\infty e^{-x^2} \\, \\mathrm{d}{x} = \\sqrt{\\pi}. \\] <ul> <li>The longer time you stare at it, the more comfortable you will be (no, not at all).</li> <li>If your CS1 course did not use Python, don't worry! Python will be very easy to learn after getting all concepts from CS1. See https://docs.python.org/tutorial/ to get started.</li> </ul>"},{"location":"#how-to-success","title":"How To Success","text":"<p>Quote from Prof. Alvarez</p> <p>The not-so-secret recipe for doing well on the exams is to work diligently on the problem sets and to stay up to date on the course material.</p>"},{"location":"#schedule-and-plans","title":"Schedule and Plans","text":"Week Lecture/Dates Schedule Topics 1 1~38/28 - 9/1 8/28 PS1 Release IntroductionDiscrete Probability 2 4~59/4 - 9/8 No class on 9/4 Labor Day9/4 PS2 Release9/5 PS1 Due9/6 Add/Drop Deadline Combinatorics 3 6~89/11 - 9/15 9/11 PS3 Release9/12 PS2 Due Random VariablesConditional Probability 4 9~119/18 - 9/22 9/18 PS3 Due 9/18 PS4 Release Important DistributionsExpected Value 5 12~149/25 - 9/29 9/25 PS4 Due9/25 PS5 Release9/27 Sample Exam 1 Release9/29 Family Weekend VarianceChernoff Bounds 6 --10/2 - 10/6 10/2 PS5 Due10/2 Review Section10/2 Drop without \"W\" Deadline10/4 Exam 110/6 Fall Break 7 15~1710/9 - 10/13 10/10 PS6 Release10/9 Fall Break10/10 Substitute Monday Schedule Continuous ProbabilityImportant Distributions 8 18~2010/16 - 10/20 10/16 PS7 Release10/17 PS6 Due Central Limit TheoremJoint Probability 9 21~2310/23 - 10/27 10/23 PS8 Release10/23 PS7 Due More Central Limit TheoremLinear Algebra 10 24~2610/30 - 11/3 10/30 PS9 Release 10/30 PS8 Due Linear AlgebraEigenvalues and PCA 11 2711/6 - 11/10 11/6 PS9 Due11/6 Review Section11/8 Exam 2 Martingales and Fraud Detection* 12 28~3011/13 - 11/17 11/13 PS10 Release Markov ChainsErgodic Markov Chains 13 3111/20 - 11/24 11/20 PS11 Release11/20 PS10 Due11/22-24 Thanksgiving Holidays Page Rank 14 32~3411/27 - 12/1 12/1 PS12 Release12/1 PS11 Due Intro to Branching ProcessesIntro to Queuing TheoryIntro to Stochastic Process 15 35~3712/4 - 12/8 12/8 PS12 Due Random WalksProbability Theory in TCS: Probability Methods* --12/11 - Study days --12/13 - (Date TBD) Exam 3"},{"location":"week-1/lec01/","title":"Lecture 1 - From Uncertainty To Probability Theory","text":"<p>Agenda</p> <ol> <li>What is randomness?</li> <li>What could be applications to the randomness?</li> <li>What will we learn throughout the semester?</li> <li>Examples of Monte Carlo simulation.</li> <li>Probability Paradoxes I - Intransitive Dice</li> </ol>"},{"location":"week-1/lec01/#readings","title":"Readings","text":"<ul> <li>[Alvarez] Chapter 1.</li> </ul>"},{"location":"week-1/lec01/#supplementary-readings","title":"Supplementary Readings","text":"<ul> <li>\ud83d\udcd6 How Randomness Improves Algorithms, Quanta Magzine, 2023.04.03.</li> <li>\ud83c\udf99\ufe0f Why Do We Need True Randomness, Quartz Podcast, 2021.10.12.</li> </ul>"},{"location":"week-1/lec02/","title":"Lecture 2 - Discrete Probability Basics","text":"<p>Agenda</p> <ol> <li>Formally define (discrete) probability space for common random objects.</li> <li>Probability Axioms.</li> <li>The na\u00efve ways of analyzing probability events.</li> <li>Probability Paradoxes II - The Monty Hall Problem</li> </ol>"},{"location":"week-1/lec02/#readings","title":"Readings","text":"<ul> <li>[Alvarez] Sections 2.1-2.2; 3.1-3.2.</li> </ul>"},{"location":"week-1/lec02/#important-termsnotations","title":"Important Terms/Notations","text":"<ul> <li>Probability Space: \\((\\Omega, P)\\)</li> <li>Sample Space: \\(\\Omega\\)</li> <li>Probability Mass Function (PMF): \\(P\\)</li> <li>(Discrete) Uniform Distribution: equiprobable outcomes</li> <li>Events: \\(E\\subseteq \\Omega\\)</li> <li>Independent Events: \\(P(E_1\\cap E_2) = P(E_1)P(E_2)\\)</li> <li>Random Variables: \\(X: \\Omega\\to \\mathbb{R}\\)</li> <li>Independent Random Variables: \\(P(X=x \\land Y=y) = P(X=x)P(Y=y)\\)</li> </ul>"},{"location":"week-1/lec02/#probability-axioms","title":"Probability Axioms","text":"<ul> <li>Non-negativity of probability: For any event \\(E\\) we have \\(P(E)\\ge 0\\).</li> <li>Probability of the sample space: \\(P(\\Omega)=1\\).</li> <li>Countable additivity: For any countable set of disjoint events \\(\\{A_1, A_2, \\ldots\\}\\) we have</li> </ul> \\[\\begin{cases} P(\\bigcup_{i=1}^n A_i) = \\sum_{i=1}^{n} P(A_i) &amp; \\text{if the set has finitely many events,}\\\\ P(\\bigcup_{i=1}^\\infty A_i) = \\sum_{i=1}^{\\infty} P(A_i) &amp; \\text{if the set has countably infinite sets.} \\end{cases} \\]"},{"location":"week-1/lec02/#naive-but-useful-ways-of-analyzing-probability-events","title":"Naive (But Useful!) Ways of Analyzing Probability Events","text":"<ul> <li>Enumerate the entire sample space.<ul> <li>Venn Diagrams</li> </ul> </li> <li>Drawing trees for coincident independent events.</li> </ul>"},{"location":"week-1/lec03/","title":"Lecture 3 - More Independent Events","text":"<p>Agenda</p> <ol> <li>When do two random events independent?</li> <li>Analyzing independent sequential experiments.</li> <li>Geometric progression.</li> <li>Discrete probability space with infinite sample space.</li> <li>Probability Paradox III - The Birthday Paradox</li> </ol>"},{"location":"week-1/lec03/#readings","title":"Readings","text":"<ul> <li>[Alvarez] Sections 2.2.2.</li> </ul>"},{"location":"week-1/lec03/#examples","title":"Examples","text":"<ul> <li>If you sample a five-letter-word from the alphabet, what is the probability where the word is in the form of consonant-vowel-consonant-vowel-consonant? (We treat the letter Y as a consonant.)</li> <li>Suppose you toss a biased coin 50 times independently. Prove that the probability of the first three coins result in heads is the same as the probability of the last three coins result in heads.</li> <li>Suppose you toss a biased coin repeatedly. What is the probability that you see a different side within the first 10 tosses?</li> </ul>"},{"location":"week-1/lec03/#three-events","title":"Three Events","text":"<ul> <li>There exists events \\(A, B, C\\) such that \\(\\{A, B, C\\}\\) are not independent but any pair of them are independent.</li> </ul>"},{"location":"week-10/lec24/","title":"Lecture 24 - Linear Algebra III: Determinants and Covariance Matrices","text":"<p>Agenda</p> <ol> <li>Inversion of matrices.</li> <li>Determinants.</li> <li>Covariance Matrices.</li> </ol>"},{"location":"week-10/lec24/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 8.1.</li> </ul>"},{"location":"week-10/lec25/","title":"Lecture 25 - Linear Algebra IV: Eigenvalues","text":"<p>Agenda</p> <ol> <li>Eigenvalues and Eigenvectors.</li> <li>Computing eigenvalues.</li> <li>Low rank approximation of a matrix.</li> </ol>"},{"location":"week-10/lec25/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 8.1.</li> </ul>"},{"location":"week-10/lec26/","title":"Lecture 26 - Principle Component Analysis","text":"<p>Agenda</p> <ol> <li>PCA.</li> </ol>"},{"location":"week-10/lec26/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 8.3.</li> </ul>"},{"location":"week-11/lec27/","title":"Lecture 27 - Martingales","text":"<p>Agenda</p> <ol> <li>Martingales.</li> <li>Optional Stopping Theorem.</li> <li>Fraud Detection.</li> </ol>"},{"location":"week-11/lec27/#reading","title":"Reading","text":"<ul> <li>Optional.</li> </ul>"},{"location":"week-11/review2/","title":"Exam 2 Review","text":"<p>Agenda</p> <ol> <li>Variance</li> <li>Chernoff bounds</li> <li>Continuous distributions</li> <li>Central Limit Theorem</li> <li>Matrix and vector space.</li> </ol>"},{"location":"week-12/lec28/","title":"Lecture 28 - Markov Chain I","text":"<p>Agenda</p> <ol> <li>State dynamics and Markov chains.</li> </ol>"},{"location":"week-12/lec28/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 9.1-9.2.</li> </ul>"},{"location":"week-12/lec29/","title":"Lecture 29 - Markov Chain II","text":"<p>Agenda</p> <ol> <li>Absorbing state.</li> <li>Equilibrium distribution.</li> </ol>"},{"location":"week-12/lec29/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 9.2-9.3.</li> </ul>"},{"location":"week-12/lec30/","title":"Lecture 30 - Markov Chain III","text":"<p>Agenda</p> <ol> <li>Ergodic Markov Chains</li> </ol>"},{"location":"week-12/lec30/#reading","title":"Reading","text":"<ul> <li>Optional.</li> </ul>"},{"location":"week-13/lec31/","title":"Lecture 31 - Page Rank","text":"<p>Agenda</p> <ol> <li>The page rank algorithm.</li> </ol>"},{"location":"week-13/lec31/#reading","title":"Reading","text":"<ul> <li>Optional.</li> </ul>"},{"location":"week-14/lec32/","title":"Lecture 32 - Intro to Branching Process","text":"<p>Agenda</p> <ol> <li>Random process</li> <li>Galton-Watson process</li> </ol>"},{"location":"week-14/lec32/#reading","title":"Reading","text":"<ul> <li>https://www.rand.org/content/dam/rand/pubs/reports/2009/R381.pdf</li> </ul>"},{"location":"week-14/lec33/","title":"Lecture 33 - Intro to Queuing Theory","text":"<p>Agenda</p> <ol> <li>Kendall's notation</li> <li>Analysis of M/M/1 Queue</li> </ol>"},{"location":"week-14/lec33/#reading","title":"Reading","text":"<ul> <li>https://www.whitman.edu/documents/Academics/Mathematics/berryrm.pdf</li> </ul>"},{"location":"week-14/lec34/","title":"Lecture 34 - Selected Stochastic Processes","text":"<p>Agenda</p> <ol> <li>Dirichlet Process</li> <li>Chinese restaurant process</li> </ol>"},{"location":"week-14/lec34/#reading","title":"Reading","text":"<ul> <li>Optional</li> </ul>"},{"location":"week-15/lec35/","title":"Lecture 35 - Random Walks","text":"<p>Agenda</p>"},{"location":"week-15/lec35/#reading","title":"Reading","text":"<ul> <li>Optional</li> </ul>"},{"location":"week-15/lec36/","title":"Lecture 36 - Intro to Network Routing","text":"<p>Agenda</p> <ol> <li>Congestion of randomized routing on a hypercube.</li> </ol>"},{"location":"week-15/lec36/#reading","title":"Reading","text":"<ul> <li>Optional</li> </ul>"},{"location":"week-15/lec37/","title":"Lecture 37 - TCS: Probability Methods &amp; Finale.","text":"<p>Agenda</p> <ol> <li>Ramsey number.</li> <li>Very brief summary on what have we learned.</li> </ol>"},{"location":"week-15/lec37/#reading","title":"Reading","text":"<ul> <li>Optional</li> </ul>"},{"location":"week-2/lec04/","title":"Lecture 4 - Basic Combinatorics","text":"<p>Agenda</p> <ol> <li>Addition principle and multiplication principles.</li> <li>The inclusion-exclusion principle.</li> <li>Permutations and Combinations.</li> <li>Counting via case analysis.</li> <li>Counting via bijection (cases reduced!)</li> </ol>"},{"location":"week-2/lec04/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 2.3.1-2.3.2.</li> </ul>"},{"location":"week-2/lec05/","title":"Lecture 5 - More Combinatorics","text":"<p>Agenda</p> <ol> <li>Binomial Coefficients.</li> <li>Factorials and Stirling's approximation.</li> <li>The derangement problem.</li> <li>Counting via recursion (counting in the CS way!)</li> </ol>"},{"location":"week-2/lec05/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 2.3.3.</li> </ul>"},{"location":"week-3/lec06/","title":"Lecture 6 - Discrete Random Variables","text":"<p>Agenda</p> <ol> <li>Random variables are functions on a probability space.</li> <li>Concepts from data science and functional programming: \"mapping\" and \"filtering\".</li> <li>Indicator random variables.</li> <li>Independent random variables.</li> <li>Concepts from randomized algorithms: Principle of Deferred Decisions.</li> </ol>"},{"location":"week-3/lec06/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 3.1-3.2.</li> </ul>"},{"location":"week-3/lec07/","title":"Lecture 7 - Conditional Probability","text":"<p>Agenda</p> <ol> <li>Definition and notation of conditional probability.</li> </ol>"},{"location":"week-3/lec07/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 6.1-6.2.</li> </ul>"},{"location":"week-3/lec08/","title":"Lecture 8 - Bayes' Rule","text":"<p>Agenda</p> <ol> <li>Bayes' Rule</li> <li>How to interpret random experiments?</li> <li>Frequentist vs. Bayesian</li> </ol>"},{"location":"week-3/lec08/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 6.1-6.2.</li> </ul>"},{"location":"week-3/lec08/#extra-reading","title":"Extra Reading","text":"<ul> <li>Frequentist and Bayesian approaches in statistics</li> <li>Bayesian vs. Frequentist in A/B Testing</li> <li>Bayes' Theorem or Bayes's Theorem</li> </ul>"},{"location":"week-4/lec09/","title":"Lecture 9 - Important Discrete Distributions","text":"<p>Agenda</p> <ol> <li>Bernoulli Distribution</li> <li>Binomial Distribution (sampling with replacement)</li> <li>Geometric Distribution</li> <li>Hypergeometric Distribution (sampling without replacement)</li> <li>Poisson Distribution</li> </ol>"},{"location":"week-4/lec09/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 3.4-3.5.</li> <li>[Straubing] http://www.cs.bc.edu/~straubin/csci2244-2019/Lecture6.pdf.</li> </ul>"},{"location":"week-4/lec10/","title":"Lecture 10 - Expected Value","text":"<p>Agenda</p> <ol> <li>Expected Values</li> <li>Linearity of Expectation</li> <li>The Coupon Collector's Problem.</li> <li>Simpson's paradox.</li> </ol>"},{"location":"week-4/lec10/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 3.6.1.</li> </ul>"},{"location":"week-4/lec11/","title":"Lecture 11 - Analyzing Randomized Algorithms","text":"<p>Agenda</p> <ol> <li>Revisiting the coupon collector's problem.</li> <li>Analysis of quicksort.</li> <li>Sampling algorithms: rejection sampling.</li> <li>Sampling algorithms: reservoir sampling.</li> <li>Designing randomized algorithms: the myth of expectation --- sharing apples.</li> </ol>"},{"location":"week-4/lec11/#reading","title":"Reading","text":"<ul> <li>[Straubing] http://www.cs.bc.edu/~straubin/csci2244-2019/Lecture8.pdf.</li> </ul>"},{"location":"week-5/lec12/","title":"Lecture 12 - Variance","text":"<p>Agenda</p> <ol> <li>Variance</li> <li>Markov's Inequality</li> <li>Chebyshev's Inequality</li> </ol>"},{"location":"week-5/lec12/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 3.6.2-3.6.4, 3.7.</li> </ul>"},{"location":"week-5/lec13/","title":"Lecture 13 - Discrete Law of Large Numbers","text":"<p>Agenda</p> <ol> <li>Law of Large Numbers</li> <li>Tail Probabilities</li> <li>Rubin-Chernoff-Hoeffding Bounds</li> </ol>"},{"location":"week-5/lec13/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 5.1, 5.2.1, 5.2.2, 5.4.</li> </ul>"},{"location":"week-5/lec14/","title":"Lecture 14 - Moments","text":"<p>Agenda</p> <ol> <li>Second Moment Methods</li> <li>Variance, Skewness, Kurtosis.</li> <li>Pair-wise independence and Pseudo Number Generators.</li> </ol>"},{"location":"week-5/lec14/#reading","title":"Reading","text":"<ul> <li>Optional</li> </ul>"},{"location":"week-6/review1/","title":"Exam 1 Review","text":"<p>Agenda</p> <ol> <li>Combinatorics</li> <li>Independent Events and Independent Random Variables</li> <li>Important Distributions</li> <li>Linearity of Expectation</li> </ol>"},{"location":"week-7/lec15/","title":"Lecture 15 - Continuous Probability","text":"<p>Agenda</p> <ol> <li>Revisit Probability Axioms.</li> <li>Probability density function (pdf).</li> <li>Cumulative density function (cdf).</li> <li>Uniform distribution.</li> <li>Buffon's Needle.</li> </ol>"},{"location":"week-7/lec15/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 4.1-4.2.2, 4.3.1.</li> </ul>"},{"location":"week-7/lec16/","title":"Lecture 16 - Gaussian Distribution","text":"<p>Agenda</p> <ol> <li>Normal distribution.</li> <li>Expectation, variance, standard deviation.</li> <li>Rotational symmetry and sampling on a circle.</li> </ol>"},{"location":"week-7/lec16/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Section 4.2.3-4.2.4, 4.3.2-4.3.3.</li> </ul>"},{"location":"week-7/lec17/","title":"Lecture 17 - Other Important Distributions","text":"<p>Agenda</p> <ol> <li>Exponential distribution.</li> <li>Beta distribution.</li> <li>The Bertrand Paradox.</li> </ol>"},{"location":"week-7/lec17/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Section 4.2.3-4.2.4, 4.3.2-4.3.4.</li> <li>https://www.stat.berkeley.edu/~aldous/Real_World/paradox.html</li> </ul>"},{"location":"week-8/lec18/","title":"Lecture 18 - Central Limit Theorem","text":"<p>Agenda</p> <ol> <li>Central Limit Theorem</li> </ol>"},{"location":"week-8/lec18/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 5.2.3.</li> </ul>"},{"location":"week-8/lec19/","title":"Lecture 19 - Joint Probability","text":"<p>Agenda</p> <ol> <li>Multi-dimensional random variable.</li> <li>Joint Gaussian distribution</li> <li>Marginal distribution</li> </ol>"},{"location":"week-8/lec19/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 7.1-7.2.</li> </ul>"},{"location":"week-8/lec20/","title":"Lecture 20 - Covariance and Correlation","text":"<p>Agenda</p> <ol> <li>Covariance and Correlation</li> </ol>"},{"location":"week-8/lec20/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 7.3-7.4.</li> </ul>"},{"location":"week-9/lec21/","title":"Lecture 21 - More Central Limit Theorems","text":"<p>Agenda</p> <ol> <li>More CLT.</li> </ol>"},{"location":"week-9/lec21/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 7.3-7.4.</li> </ul>"},{"location":"week-9/lec22/","title":"Lecture 22 - Linear Algebra I: Matrices","text":"<p>Agenda</p> <ol> <li>Definition of matrix multiplications.</li> <li>Counting walks on a graph.</li> <li>Permutation matrix.</li> <li>Singly &amp; doubly stochastic matrix.</li> <li>2D &amp; 3D Geometry - rotational matrix</li> </ol>"},{"location":"week-9/lec22/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 8.1.</li> </ul>"},{"location":"week-9/lec23/","title":"Lecture 23 - Linear Algebra II: Vector Space","text":"<p>Agenda</p> <ol> <li>Vectors.</li> <li>Inner product.</li> <li>Vector space view of matrices.</li> <li>Linear transforms.</li> <li>Rank.</li> </ol>"},{"location":"week-9/lec23/#reading","title":"Reading","text":"<ul> <li>[Alvarez] Sections 8.2.</li> </ul>"}]}